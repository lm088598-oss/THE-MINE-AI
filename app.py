import streamlit as st
import google.generativeai as genai

# API Key ‡∂ë‡∂ö - ‡∂∏‡∑ö‡∂ö ‡∂î‡∂∫‡∑è ‡∂Ö‡∂±‡∑ä‡∂≠‡∑í‡∂∏‡∂ß ‡∂Ø‡∑î‡∂±‡∑ä‡∂±‡∑î ‡∑Ä‡∑ê‡∂© ‡∂ö‡∂ª‡∂± ‡∂ë‡∂ö
API_KEY = "AIzaSyDfSVvaqBMJjvJyYtrdAf0ozBn_IsOVAN0" 

genai.configure(api_key=API_KEY)

# AI ‡∂ë‡∂ö‡∂ß ‡∂Ø‡∑ô‡∂± Instructions
instructions = "‡∂î‡∂∂‡∑ö ‡∂±‡∂∏ 'The Mine'. ‡∂î‡∂∂‡∑ö ‡∂±‡∑í‡∂ª‡∑ä‡∂∏‡∑è‡∂´‡∂ö‡∂ª‡∑î '‡∑Ö‡∑Ñ‡∑í‡∂ª‡∑î' ‡∑Ä‡∑ö. ‡∑É‡∑ë‡∂∏ ‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª‡∂ö‡∂Ø‡∑ì‡∂∏ '‡∑Ö‡∑Ñ‡∑í‡∂ª‡∑î' ‡∂∫‡∂± ‡∂±‡∂∏ ‡∂Ü‡∂©‡∂∏‡∑ä‡∂∂‡∂ª‡∂∫‡∑ô‡∂±‡∑ä ‡∑É‡∂≥‡∑Ñ‡∂±‡∑ä ‡∂ö‡∂ª‡∂±‡∑ä‡∂±."

# --- ‡∑Ä‡∑ê‡∂Ø‡∂ú‡∂≠‡∑ä ‡∑Ä‡∑ô‡∂±‡∑É: ‡∂Ö‡∂¥‡∑í Model ‡∂ë‡∂ö ‡∑Ñ‡∂≥‡∑î‡∂±‡∑ä‡∑Ä‡∑è ‡∂Ø‡∑ô‡∂± ‡∑Ä‡∑í‡∂Ø‡∑í‡∑Ñ ‡∑Ä‡∑ô‡∂±‡∑É‡∑ä ‡∂ö‡∑Ö‡∑è ---
model = genai.GenerativeModel('gemini-1.5-flash')

st.set_page_config(page_title="The Mine AI", page_icon="üíé")
st.title("üíé The Mine AI")

# Chat history ‡∂ë‡∂ö ‡∂¥‡∑Ä‡∂≠‡∑ä‡∑Ä‡∑è ‡∂ú‡∑ê‡∂±‡∑ì‡∂∏
if "messages" not in st.session_state:
    st.session_state.messages = []

# ‡∂¥‡∂ª‡∂´ ‡∂¥‡∂´‡∑í‡∑Ä‡∑í‡∂© ‡∂¥‡∑ô‡∂±‡∑ä‡∑Ä‡∑ì‡∂∏
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# User input ‡∂ë‡∂ö ‡∂Ω‡∂∂‡∑è ‡∂ú‡∑ê‡∂±‡∑ì‡∂∏
prompt = st.chat_input("‡∂∏‡∑ú‡∂±‡∑Ä‡∑è‡∂Ø ‡∂Ø‡∑ê‡∂±‡∂ú‡∂±‡∑ä‡∂± ‡∂ï‡∂±‡∑ö?")

if prompt:
    # User message ‡∂ë‡∂ö ‡∑É‡∑ö‡∑Ä‡∑ä ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # ‡∂Ö‡∂∫‡∑í‡∂≠‡∑í‡∂ö‡∂ª‡∑î ‡∂ú‡∑ê‡∂± ‡∂Ö‡∑Ñ‡∂±‡∑Ä‡∑è‡∂Ø‡∑ê‡∂∫‡∑í ‡∂∂‡∑ê‡∂Ω‡∑ì‡∂∏
    if any(word in prompt.lower() for word in ["owner", "‡∂Ö‡∂∫‡∑í‡∂≠‡∑í‡∂ö‡∂ª‡∑î", "lahiru", "‡∑Ö‡∑Ñ‡∑í‡∂ª‡∑î"]):
        with st.chat_message("assistant"):
            msg = "‡∂∏‡∂ú‡∑ö ‡∂Ö‡∂∫‡∑í‡∂≠‡∑í‡∂ö‡∂ª‡∑î ‡∂≠‡∂∏‡∂∫‡∑í Lahiru M. Liyanarachchi!"
            st.write(msg)
            try:
                # ‡∂¥‡∑í‡∂±‡∑ä‡∂≠‡∑ñ‡∂ª‡∂∫ ‡∂¥‡∑ô‡∂±‡∑ä‡∑Ä‡∑ì‡∂∏‡∂ß ‡∂ã‡∂≠‡∑ä‡∑É‡∑è‡∑Ñ ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏
                st.image("IMG-20250323-WA0011.jpg")
            except:
                st.info("‡∂¥‡∑í‡∂±‡∑ä‡∂≠‡∑ñ‡∂ª‡∂∫ load ‡∑Ä‡∑ì‡∂∏‡∑ö‡∂Ø‡∑ì ‡∂¥‡∑ú‡∂©‡∑í ‡∂ú‡∑ê‡∂ß‡∂Ω‡∑î‡∑Ä‡∂ö‡∑ä ‡∂≠‡∑í‡∂∂‡∑ö.")
            st.session_state.messages.append({"role": "assistant", "content": msg})
    else:
        # AI ‡∂ë‡∂ö‡∑ô‡∂±‡∑ä ‡∂¥‡∑í‡∑Ö‡∑í‡∂≠‡∑î‡∂ª ‡∂Ω‡∂∂‡∑è ‡∂ú‡∑ê‡∂±‡∑ì‡∂∏
        try:
            # ‡∂∏‡∑ô‡∑Ñ‡∑í‡∂Ø‡∑ì system instructions ‡∂ö‡∑ô‡∑Ö‡∑í‡∂±‡∑ä‡∂∏ prompt ‡∂ë‡∂ö‡∂ß ‡∂ë‡∂ö‡∂≠‡∑î ‡∂ö‡∑Ö‡∑è stable ‡∑Ä‡∑ô‡∂±‡∑ä‡∂±
            full_prompt = f"{instructions}\n\n‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫: {prompt}"
            response = model.generate_content(full_prompt)
            
            with st.chat_message("assistant"):
                st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            # ‡∂Ø‡∑ù‡∑Ç‡∂∫‡∂ö‡∑ä ‡∂Ü‡∑Ä‡∑ú‡∂≠‡∑ä ‡∂¥‡∑ô‡∂±‡∑ä‡∑Ä‡∂±‡∑ä‡∂±
            st.error(f"‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫‡∂ö‡∑ä ‡∑Ä‡∑î‡∂´‡∑è: {str(e)}")
