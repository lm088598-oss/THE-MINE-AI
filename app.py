import streamlit as st
import google.generativeai as genai

# API Key ‡∂ë‡∂ö
API_KEY = "AIzaSyDfSVvaqBMJjvJyYtrdAf0ozBn_IsOVAN0"
genai.configure(api_key=API_KEY)

# --- ‡∂∏‡∑ô‡∂±‡∑ä‡∂± ‡∂∏‡∑ô‡∂≠‡∂±‡∂∫‡∑í ‡∑Ä‡∑ô‡∂±‡∑É ‡∂≠‡∑í‡∂∫‡∑ô‡∂±‡∑ä‡∂±‡∑ö ---
# ‡∂¥‡∂Ø‡∑ä‡∂∞‡∂≠‡∑í‡∂∫ ‡∑Ä‡∑í‡∑É‡∑í‡∂±‡∑ä ‡∂¥‡∑í‡∑Ö‡∑í‡∂ú‡∂±‡∑ä‡∂±‡∑è ‡∂ï‡∂±‡∑ë‡∂∏ ‡∂±‡∂∏‡∂ö‡∑ä ‡∑É‡∑ú‡∂∫‡∑è ‡∂ú‡∑ê‡∂±‡∑ì‡∂∏‡∂ß ‡∂ã‡∂≠‡∑ä‡∑É‡∑è‡∑Ñ ‡∂ö‡∂ª‡∂∫‡∑í
model_to_use = "gemini-1.5-flash" # Default ‡∂±‡∂∏

try:
    # Google ‡∑Ä‡∑í‡∑É‡∑í‡∂±‡∑ä ‡∂Ω‡∂∂‡∑è ‡∂Ø‡∑ô‡∂± models list ‡∂ë‡∂ö ‡∂¥‡∂ª‡∑ì‡∂ö‡∑ä‡∑Ç‡∑è ‡∂ö‡∑í‡∂ª‡∑ì‡∂∏
    available_models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
    if 'models/gemini-1.5-flash' in available_models:
        model_to_use = 'models/gemini-1.5-flash'
    elif 'models/gemini-pro' in available_models:
        model_to_use = 'models/gemini-pro'
except:
    # List ‡∂ë‡∂ö ‡∂ú‡∂±‡∑ä‡∂± ‡∂∂‡∑ê‡∂ª‡∑í ‡∑Ä‡∑î‡∂´‡∑ú‡∂≠‡∑ä ‡∑Ä‡∂©‡∑è‡∂≠‡∑ä ‡∑É‡∑ä‡∂Æ‡∑è‡∑Ä‡∂ª ‡∂±‡∂∏ ‡∂¥‡∑è‡∑Ä‡∑í‡∂†‡∑ä‡∂†‡∑í ‡∂ö‡∂ª‡∂∫‡∑í
    model_to_use = "gemini-pro" 

model = genai.GenerativeModel(model_to_use)

# Page Setup
st.set_page_config(page_title="The Mine AI", page_icon="üíé")
st.title("üíé The Mine AI")

if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

prompt = st.chat_input("‡∂∏‡∑ú‡∂±‡∑Ä‡∑è‡∂Ø ‡∂Ø‡∑ê‡∂±‡∂ú‡∂±‡∑ä‡∂± ‡∂ï‡∂±‡∑ö?")

if prompt:
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # 1. ‡∂Ö‡∂∫‡∑í‡∂≠‡∑í‡∂ö‡∂ª‡∑î ‡∂ú‡∑ê‡∂± ‡∂Ö‡∑Ñ‡∂±‡∑Ä‡∑è ‡∂±‡∂∏‡∑ä (‡∂∏‡∑ô‡∂∫ ‡∂ö‡∑ô‡∂Ω‡∑í‡∂±‡∑ä‡∂∏ ‡∂ö‡∑ä‚Äç‡∂ª‡∑í‡∂∫‡∑è ‡∂ö‡∂ª‡∂∫‡∑í)
    owner_keywords = ["owner", "‡∂Ö‡∂∫‡∑í‡∂≠‡∑í‡∂ö‡∂ª‡∑î", "‡∂ö‡∑Ä‡∑î‡∂Ø ‡∑Ñ‡∑ê‡∂Ø‡∑î‡∑Ä‡∑ö", "lahiru", "‡∑Ö‡∑Ñ‡∑í‡∂ª‡∑î", "aitikaru"]
    if any(word in prompt.lower() for word in owner_keywords):
        with st.chat_message("assistant"):
            res = "‡∂∏‡∂ú‡∑ö ‡∂Ö‡∂∫‡∑í‡∂≠‡∑í‡∂ö‡∂ª‡∑î ‡∂≠‡∂∏‡∂∫‡∑í Lahiru M. Liyanarachchi!"
            st.markdown(f"**{res}**")
            try:
                st.image("IMG-20250323-WA0011.jpg")
            except:
                pass
            st.session_state.messages.append({"role": "assistant", "content": res})

    # 2. ‡∑Ä‡∑ô‡∂±‡∂≠‡∑ä ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂± ‡∑É‡∂≥‡∑Ñ‡∑è
    else:
        try:
            # 'instructions' ‡∑Ä‡∑ô‡∂±‡∑î‡∑Ä‡∂ß ‡∂ö‡∑ô‡∂Ω‡∑í‡∂±‡∑ä‡∂∏ prompt ‡∂ë‡∂ö ‡∂∫‡∑Ä‡∂∏‡∑î ‡∂≠‡∑Ñ‡∑Ä‡∑î‡∂ª‡∑î ‡∂ö‡∂ª‡∂ú‡∂±‡∑ä‡∂±
            response = model.generate_content(f"‡∂î‡∂∂‡∑ö ‡∂±‡∂∏ 'The Mine'. ‡∂±‡∑í‡∂ª‡∑ä‡∂∏‡∑è‡∂´‡∂ö‡∂ª‡∑î '‡∑Ö‡∑Ñ‡∑í‡∂ª‡∑î'. ‡∂¥‡∑ä‚Äç‡∂ª‡∑Å‡∑ä‡∂±‡∂∫: {prompt}")
            with st.chat_message("assistant"):
                st.markdown(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            # ‡∂≠‡∑Ä‡∂∏‡∂≠‡∑ä error ‡∂ë‡∂ö‡∂ö‡∑ä ‡∂ë‡∂±‡∑Ä‡∑è ‡∂±‡∂∏‡∑ä ‡∂±‡∂∏ ‡∂∏‡∑è‡∂ª‡∑î ‡∂ö‡∂ª‡∂∏‡∑î
            st.error("AI ‡∂≠‡∑è‡∂ö‡∑ä‡∑Ç‡∂´‡∑í‡∂ö ‡∂Ø‡∑ù‡∑Ç‡∂∫‡∂ö‡∑ä. ‡∂ö‡∂ª‡∑î‡∂´‡∑è‡∂ö‡∂ª 'gemini-pro' ‡∂Ω‡∑ô‡∑É ‡∂∏‡∑è‡∂ª‡∑î ‡∑Ä‡∑ì ‡∂±‡∑ê‡∑Ä‡∂≠ ‡∂ã‡∂≠‡∑ä‡∑É‡∑è‡∑Ñ ‡∂ö‡∂ª‡∂±‡∑ä‡∂±.")
            st.info(f"Model used: {model_to_use} | Error: {e}")
